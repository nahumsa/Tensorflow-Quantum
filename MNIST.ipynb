{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcDE2SV+1+wDmIulxnzH1d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nahumsa/Tensorflow-Quantum/blob/master/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0PXNyDYxdVw",
        "colab_type": "text"
      },
      "source": [
        "# Supervised learning using Quantum Neural Networks\n",
        "\n",
        "This code is based on this [notebook](https://github.com/tensorflow/quantum/blob/master/docs/tutorials/mnist.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcrGoRdhZIXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow==2.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQVSFooIyFQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-quantum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_vhXGoOyH6f",
        "colab_type": "code",
        "outputId": "6bc915e2-5be7-4cb1-ec57-3121443fc150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import collections\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3sxgOPEyNFg",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data\n",
        "In this tutorial we shall classify between numbers 1 and 3 on the MNIST.\n",
        "\n",
        "The procedure will be: \n",
        "\n",
        "    1.1) Load data from keras.datasets\n",
        "    1.2) Filter only the numbers that we want to classify\n",
        "    1.3) Rescale images to fit on a Quantum Computer\n",
        "    1.4) Remove contradictory examples\n",
        "    1.5) Convert to binary and then to Quantum Circuits\n",
        "    1.6) Convert to tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuOg75zP0HNp",
        "colab_type": "text"
      },
      "source": [
        "## 1.1) Load data from keras.datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDejJmLbydXo",
        "colab_type": "code",
        "outputId": "74c7f199-0200-4928-e72d-6ef5f61e3125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize\n",
        "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
        "\n",
        "print(\"Number of original training examples:\", len(x_train))\n",
        "print(\"Number of original test examples:\", len(x_train))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Number of original training examples: 60000\n",
            "Number of original test examples: 60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIHry3qT0Ke3",
        "colab_type": "text"
      },
      "source": [
        "## 1.2) Filter only the numbers that we want to classify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlrYivgz0pdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_13(x,y):\n",
        "  mask = (y == 1) | (y == 3)\n",
        "  x,y = x[mask], y[mask]\n",
        "  #Convert y to binary \n",
        "  y = (y == 3)\n",
        "  return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJdxDhB61Idf",
        "colab_type": "code",
        "outputId": "36e65259-bee4-4182-a84c-4f6830dec74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x_train, y_train = filter_13(x_train, y_train)\n",
        "x_test, y_test = filter_13(x_test, y_test)\n",
        "\n",
        "print(f\"Number of filtered training examples: {x_train.shape[0]}\")\n",
        "print(f\"Number of filtered test examples: {x_test.shape[0]}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of filtered training examples: 12873\n",
            "Number of filtered test examples: 2145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-bHekRF0UjX",
        "colab_type": "text"
      },
      "source": [
        "## 1.3) Rescale images to fit on a Quantum Computer\n",
        "\n",
        "To resize the image we use the `tf.image.resize` and we need to use `.numpy()` in order to convert from `tf.Tensor` to `np.arrays`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJreDqjx0qaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_small = tf.image.resize(x_train, (4,4)).numpy()\n",
        "x_test_small = tf.image.resize(x_test, (4,4)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usmg7Xej23X0",
        "colab_type": "code",
        "outputId": "382d0867-bab8-452d-e730-890e9f58045e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "plt.imshow(x_train_small[0,:,:,0], vmin=0, vmax=1)\n",
        "plt.title(f'{y_train[0]} \\nFalse = 1, True = 3', size=20)\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H0qUvlQ0UyS",
        "colab_type": "text"
      },
      "source": [
        "## 1.4) Remove contradictory examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjkETciW0q5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_contradicting(xs, ys):\n",
        "    mapping = collections.defaultdict(set)\n",
        "    # Determine the set of labels for each unique image:\n",
        "    for x,y in zip(xs,ys):\n",
        "       mapping[tuple(x.flatten())].add(y)\n",
        "    \n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    for x,y in zip(xs, ys):\n",
        "      #Check if you get the same label after applying the same X\n",
        "      labels = mapping[tuple(x.flatten())]\n",
        "      if len(labels) == 1:\n",
        "          new_x.append(x)\n",
        "          new_y.append(list(labels)[0])\n",
        "      else:\n",
        "          # Throw out images that match more than one label.\n",
        "          pass\n",
        "    \n",
        "    num_1 = sum(1 for value in mapping.values() if True in value)\n",
        "    num_3 = sum(1 for value in mapping.values() if False in value)\n",
        "    num_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
        "\n",
        "    print(\"Number of unique images:\", len(mapping.values()))\n",
        "    print(\"Number of 1s: \", num_1)\n",
        "    print(\"Number of 3s: \", num_3)\n",
        "    print(\"Number of contradictory images: \", num_both)\n",
        "    print()\n",
        "    print(\"Initial number of examples: \", len(xs))\n",
        "    print(\"Remaining non-contradictory examples: \", len(new_x))\n",
        "    \n",
        "    return np.array(new_x), np.array(new_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uliekcve58ee",
        "colab_type": "code",
        "outputId": "00592308-b6ab-47af-9a86-6c62559ffca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "x_train_nocon, y_train_nocon = remove_contradicting(x_train_small, y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique images: 6851\n",
            "Number of 1s:  4961\n",
            "Number of 3s:  2176\n",
            "Number of contradictory images:  286\n",
            "\n",
            "Initial number of examples:  12873\n",
            "Remaining non-contradictory examples:  7907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yjQ_NGD0U92",
        "colab_type": "text"
      },
      "source": [
        "## 1.5) Convert to binary and then to Quantum Circuits\n",
        "Since the images are between 0 and 1, we have to set a threshold to transform the image into binary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hqwoeTT0rOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = 0.5\n",
        "\n",
        "x_train_bin = np.array(x_train_nocon > threshold)\n",
        "x_test_bin = np.array(x_test_small > threshold)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7k9ADL58d0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert2circuit(image):\n",
        "  values = image.flatten()\n",
        "  qubits = cirq.GridQubit.rect(4,4)\n",
        "  circuit = cirq.Circuit()\n",
        "  for i,val in enumerate(values):\n",
        "    if val:\n",
        "      circuit.append(cirq.X(qubits[i]))\n",
        "  return circuit\n",
        "\n",
        "x_train_circ = [convert2circuit(x) for x in x_train_bin]\n",
        "x_test_circ = [convert2circuit(x) for x in x_test_bin]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6nV1qQb9lKE",
        "colab_type": "code",
        "outputId": "55d81e16-60ea-4a30-ef46-d49ec17f02d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "bin_img = x_train_bin[0,:,:,0]\n",
        "indices = np.array(np.where(bin_img)).T\n",
        "print(f'The indices shoud be: {[i for i in indices]}')\n",
        "SVGCircuit(x_train_circ[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The indices shoud be: [array([1, 2]), array([3, 1])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7ff2a0685fd0>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"169.517734375\" height=\"100.0\"><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(1, 2): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(3, 1): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\">X</text><rect x=\"79.517734375\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\">X</text></svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JSAsOye0VIL",
        "colab_type": "text"
      },
      "source": [
        "## 1.6) Convert to tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_bzebpQ0rrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
        "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz0mNlo9-N2H",
        "colab_type": "text"
      },
      "source": [
        "# 2) Quantum Neural Network (QNN)\n",
        "\n",
        "For the QNN we will follow the TFQ whitepaper. That is, we construct a Parametrized Quantum Circuit (PQC) which is done by the `CircuitLayerBuild` to create layers with entangling gates through all qubits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPHgHe6l_21Q",
        "colab_type": "text"
      },
      "source": [
        "## 2.1) Model circuit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwS69FPfAsH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CircuitLayerBuilder():\n",
        "    def __init__(self, data_qubits, readout):\n",
        "        self.data_qubits = data_qubits\n",
        "        self.readout = readout\n",
        "    \n",
        "    def add_layer(self, circuit, gate, prefix):\n",
        "        for i, qubit in enumerate(self.data_qubits):\n",
        "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
        "            circuit.append(gate(qubit, self.readout)**symbol)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To7CBbPqAvi1",
        "colab_type": "code",
        "outputId": "86ab96d5-a356-4b81-8609-d2b1f568631a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "demo_builder = CircuitLayerBuilder(data_qubits = cirq.GridQubit.rect(4,1),\n",
        "                                   readout= cirq.GridQubit(-1,-1))\n",
        "\n",
        "circuit = cirq.Circuit()\n",
        "demo_builder.add_layer(circuit, gate = cirq.XX, prefix='xx')\n",
        "SVGCircuit(circuit)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7ff257232be0>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"522.59953125\" height=\"250.0\"><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"129.99353515625\" x2=\"129.99353515625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"230.73810546875004\" x2=\"230.73810546875004\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"331.48267578125007\" x2=\"331.48267578125007\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"432.22724609375007\" x2=\"432.22724609375007\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(0, 0): </text><rect x=\"10.0\" y=\"105.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(1, 0): </text><rect x=\"10.0\" y=\"155.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(2, 0): </text><rect x=\"10.0\" y=\"205.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(3, 0): </text><rect x=\"89.62125\" y=\"55.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX^(xx-0)</text><rect x=\"89.62125\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX</text><rect x=\"190.36582031250003\" y=\"105.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX^(xx-1)</text><rect x=\"190.36582031250003\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX</text><rect x=\"291.11039062500004\" y=\"155.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX^(xx-2)</text><rect x=\"291.11039062500004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX</text><rect x=\"391.85496093750004\" y=\"205.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX^(xx-3)</text><rect x=\"391.85496093750004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">XX</text></svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EirBkaaDi_Gk",
        "colab_type": "text"
      },
      "source": [
        "Here we will build a 4x4 circuit with XX and ZZ gates with readout on the (-1,-1) qubit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAxOOppDAzQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_quantum_model():\n",
        "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
        "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
        "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
        "    circuit = cirq.Circuit()\n",
        "    \n",
        "    # Prepare the readout qubit.\n",
        "    circuit.append(cirq.X(readout))\n",
        "    circuit.append(cirq.H(readout))\n",
        "    \n",
        "    builder = CircuitLayerBuilder(\n",
        "        data_qubits = data_qubits,\n",
        "        readout= readout)\n",
        "\n",
        "    # Then add layers (experiment by adding more).\n",
        "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
        "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
        "\n",
        "    # Finally, prepare the readout qubit.\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    return circuit, cirq.Z(readout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkwOfvRfBRyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_circuit, model_readout = create_quantum_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2C0av1wBS3r",
        "colab_type": "text"
      },
      "source": [
        "## 2.2) Wrapping on a Keras Model\n",
        "\n",
        "To wrap our PQC into a keras model, we use the `tfq.layers.PQC` which gets a parametrized circuit and outputs the readout of this optimized PQC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1BQQ2MFBTiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the Keras model.\n",
        "model_q = tf.keras.Sequential([\n",
        "    # The input is the data-circuit, encoded as a tf.string\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
        "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
        "    tfq.layers.PQC(model_circuit, model_readout),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kR-RQXci-VU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "af0b48d6-4d62-472f-b8bf-bb4724ca694e"
      },
      "source": [
        "model_q.compile(\n",
        "    loss= tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "model_q.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "pqc_2 (PQC)                  (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 32\n",
            "Trainable params: 32\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iwM1GkrjNbD",
        "colab_type": "text"
      },
      "source": [
        "## 2.3) Training the quantum Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8fD4Qx8jUUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "NUM_EXAMPLES = 500 #len(x_train_tfcirc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZnJcL2NjmQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
        "x_test_tfcirc_sub = x_test_tfcirc[:NUM_EXAMPLES]\n",
        "y_train_sub = y_train_nocon[:NUM_EXAMPLES]\n",
        "y_test_sub = y_test[:NUM_EXAMPLES]\n",
        "y_train_sub = y_train_sub.astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEhKflqlkN-P",
        "colab_type": "code",
        "outputId": "78b3059f-9c26-442e-cf8c-b254f5b96bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "qnn_history = model_q.fit(\n",
        "      x_train_tfcirc_sub, y_train_sub,\n",
        "      batch_size=BATCH_SIZE,\n",
        "      epochs=EPOCHS,\n",
        "      verbose=1,\n",
        "      validation_data=(x_test_tfcirc_sub, y_test_sub))\n",
        "\n",
        "qnn_results = model_q.evaluate(x_test_tfcirc, y_test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 500 samples, validate on 500 samples\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 285s 571ms/sample - loss: 3.8020 - accuracy: 0.3840 - val_loss: 2.2182 - val_accuracy: 0.5300\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 285s 569ms/sample - loss: 2.9503 - accuracy: 0.3840 - val_loss: 2.1189 - val_accuracy: 0.5300\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 285s 571ms/sample - loss: 2.8082 - accuracy: 0.3840 - val_loss: 2.0680 - val_accuracy: 0.5300\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 285s 571ms/sample - loss: 2.1676 - accuracy: 0.3840 - val_loss: 1.2992 - val_accuracy: 0.5300\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 285s 571ms/sample - loss: 2.0611 - accuracy: 0.3840 - val_loss: 1.2650 - val_accuracy: 0.5300\n",
            "2145/2145 [==============================] - 38s 18ms/sample - loss: 1.5153 - accuracy: 0.5291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d15ZyrOglBqv",
        "colab_type": "text"
      },
      "source": [
        "# 3) Classical Neural Net\n",
        "\n",
        "Let's compare the QNN with a simple FCN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8TzM3MJkyJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "5302a2dc-5397-4be5-9199-b64b162a3974"
      },
      "source": [
        "def create_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "model_c = create_classical_model()\n",
        "model_c.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_c.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,198,721\n",
            "Trainable params: 1,198,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0FWA4jbkzcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "cbc6ce70-1392-4f91-9519-a97803136fa8"
      },
      "source": [
        "model_c.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=128,\n",
        "          epochs=1,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "cnn_results = model_c.evaluate(x_test, y_test)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 12873 samples, validate on 2145 samples\n",
            "12873/12873 [==============================] - 3s 204us/sample - loss: 0.0553 - accuracy: 0.9827 - val_loss: 0.0063 - val_accuracy: 0.9986\n",
            "2145/2145 [==============================] - 0s 119us/sample - loss: 0.0063 - accuracy: 0.9986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4YkvtUbk2YC",
        "colab_type": "text"
      },
      "source": [
        "The previous model is unfair, because we are comparing 1k parameters with only 16 parameters on the QNN. Thus we construct a more 'fair' model that is simillar to the accuracy obtained by the QNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBaT5v37k_NC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "967bc21a-fdba-4e9c-e62a-8b7a534bb3be"
      },
      "source": [
        "def create_fair_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(4,4,1)))\n",
        "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "model_cf = create_fair_classical_model()\n",
        "model_cf.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_cf.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_4 (Flatten)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 34        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 37\n",
            "Trainable params: 37\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zpiTsm6k_lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "52e46eaa-f372-4c2b-9aab-fef45ca5e108"
      },
      "source": [
        "model_cf.fit(x_train_bin,\n",
        "          y_train_nocon,\n",
        "          batch_size=128,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=2,\n",
        "          validation_data=(x_test_bin, y_test))\n",
        "\n",
        "fair_nn_results = model_cf.evaluate(x_test_bin, y_test)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7907 samples, validate on 2145 samples\n",
            "Epoch 1/5\n",
            "7907/7907 - 1s - loss: 0.7342 - accuracy: 0.3424 - val_loss: 0.7171 - val_accuracy: 0.5291\n",
            "Epoch 2/5\n",
            "7907/7907 - 0s - loss: 0.7012 - accuracy: 0.3430 - val_loss: 0.7116 - val_accuracy: 0.5301\n",
            "Epoch 3/5\n",
            "7907/7907 - 0s - loss: 0.6672 - accuracy: 0.3637 - val_loss: 0.7048 - val_accuracy: 0.5608\n",
            "Epoch 4/5\n",
            "7907/7907 - 0s - loss: 0.6226 - accuracy: 0.5307 - val_loss: 0.7020 - val_accuracy: 0.6709\n",
            "Epoch 5/5\n",
            "7907/7907 - 0s - loss: 0.5916 - accuracy: 0.7122 - val_loss: 0.7023 - val_accuracy: 0.5333\n",
            "2145/2145 [==============================] - 0s 85us/sample - loss: 0.7023 - accuracy: 0.5333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaTWk4pGlBkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e0bb2dc2-a50e-4521-f268-6c01f4e46300"
      },
      "source": [
        "qnn_accuracy = qnn_results[1]\n",
        "cnn_accuracy = cnn_results[1]\n",
        "fair_nn_accuracy = fair_nn_results[1]\n",
        "\n",
        "sns.barplot([\"Quantum\", \"Classical, full\", \"Classical, fair\"],\n",
        "            [qnn_accuracy, cnn_accuracy, fair_nn_accuracy])\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}